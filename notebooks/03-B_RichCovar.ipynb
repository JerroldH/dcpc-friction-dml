{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c126f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "print(\"pandas\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06e8dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ..\\outputs\\day_inperson_ready.csv shape: (8247, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_date</th>\n",
       "      <th>day_total_amount</th>\n",
       "      <th>n_tx</th>\n",
       "      <th>n_low_tx</th>\n",
       "      <th>T_share_low</th>\n",
       "      <th>Y_log_amt</th>\n",
       "      <th>_weekday</th>\n",
       "      <th>mshare_1</th>\n",
       "      <th>mshare_2</th>\n",
       "      <th>mshare_3</th>\n",
       "      <th>mshare_4</th>\n",
       "      <th>mshare_5</th>\n",
       "      <th>mshare_6</th>\n",
       "      <th>mshare_7</th>\n",
       "      <th>mshare_8</th>\n",
       "      <th>mshare_9</th>\n",
       "      <th>mshare_10</th>\n",
       "      <th>mshare_12</th>\n",
       "      <th>mshare_13</th>\n",
       "      <th>mshare_14</th>\n",
       "      <th>mshare_15</th>\n",
       "      <th>mshare_16</th>\n",
       "      <th>mshare_17</th>\n",
       "      <th>mshare_18</th>\n",
       "      <th>mshare_19</th>\n",
       "      <th>mshare_20</th>\n",
       "      <th>mshare_21</th>\n",
       "      <th>T_share_low_trim</th>\n",
       "      <th>active_persons</th>\n",
       "      <th>w_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>2024-10-13</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>249</td>\n",
       "      <td>1.207712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>40.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.719409</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>258</td>\n",
       "      <td>1.251364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>288</td>\n",
       "      <td>1.396872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id      _date  day_total_amount  n_tx  n_low_tx  T_share_low  \\\n",
       "0  100001 2024-10-13             50.00     1         0          0.0   \n",
       "1  100001 2024-10-14             40.24     1         1          1.0   \n",
       "2  100003 2024-10-27             18.00     1         0          0.0   \n",
       "\n",
       "   Y_log_amt  _weekday  mshare_1  mshare_2  mshare_3  mshare_4  mshare_5  \\\n",
       "0   3.931826         6       0.0       0.0       0.0       0.0       0.0   \n",
       "1   3.719409         0       1.0       0.0       0.0       0.0       0.0   \n",
       "2   2.944439         6       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   mshare_6  mshare_7  mshare_8  mshare_9  mshare_10  mshare_12  mshare_13  \\\n",
       "0       0.0       0.0       0.0       0.0        0.0        0.0        0.0   \n",
       "1       0.0       0.0       0.0       0.0        0.0        0.0        0.0   \n",
       "2       0.0       0.0       0.0       0.0        0.0        0.0        0.0   \n",
       "\n",
       "   mshare_14  mshare_15  mshare_16  mshare_17  mshare_18  mshare_19  \\\n",
       "0        0.0        0.0        0.0        1.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        1.0        0.0        0.0        0.0   \n",
       "\n",
       "   mshare_20  mshare_21  T_share_low_trim  active_persons     w_day  \n",
       "0        0.0        0.0              0.05             249  1.207712  \n",
       "1        0.0        0.0              0.95             258  1.251364  \n",
       "2        0.0        0.0              0.05             288  1.396872  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "CAND_PATHS = [\n",
    "    Path(\"../outputs/day_inperson_ready.csv\"),\n",
    "]\n",
    "\n",
    "for p in CAND_PATHS:\n",
    "    if p.exists():\n",
    "        DAY_PATH = p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"找不到 day_inperson_ready.csv，请将其放到 outputs/ 下或修改路径。\")\n",
    "\n",
    "day_ip = pd.read_csv(DAY_PATH, low_memory=False)\n",
    "# 尝试日期转型（若存在）\n",
    "for c in [\"_date\",\"date\"]:\n",
    "    if c in day_ip.columns:\n",
    "        day_ip[c] = pd.to_datetime(day_ip[c], errors=\"coerce\")\n",
    "        if c != \"_date\":\n",
    "            day_ip.rename(columns={c:\"_date\"}, inplace=True)\n",
    "\n",
    "print(\"Loaded:\", DAY_PATH, \"shape:\", day_ip.shape)\n",
    "day_ip.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047075e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, dtype=np.float32)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a25021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_bootstrap_theta(df, X_cols, T_col, Y_col, B=100, seed=2027, use_day_weight=True):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    ids = df[\"_id\"].unique()\n",
    "    thetas = []\n",
    "\n",
    "    for b in range(B):\n",
    "        samp_ids = rng.choice(ids, size=len(ids), replace=True)\n",
    "        sub = df[df[\"_id\"].isin(samp_ids)].dropna(subset=X_cols + [T_col, Y_col]).copy()\n",
    "\n",
    "        sw = None\n",
    "        if use_day_weight and \"w_day\" in sub.columns:\n",
    "            sw = sub[\"w_day\"].values\n",
    "\n",
    "        th, _, _ = dml_partialling_out_weighted(\n",
    "            sub[X_cols], sub[T_col].values, sub[Y_col].values,\n",
    "            sample_weight=sw, n_splits=5, seed=42 + b\n",
    "        )\n",
    "        thetas.append(th)\n",
    "\n",
    "    thetas = np.array(thetas)\n",
    "    ci = (np.percentile(thetas, 2.5), np.percentile(thetas, 97.5))\n",
    "    return float(thetas.mean()), (float(ci[0]), float(ci[1])), len(thetas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d842cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dml_partialling_out_weighted(X_df, T, Y, sample_weight=None, n_splits=5, seed=42):\n",
    "    \"\"\"\n",
    "    Return theta = E[(T - ê(X)) (Y - m̂(X))] / E[(T - ê(X))^2]\n",
    "    ê, m̂ 用随机森林回归（可替换为更强模型）\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    n = len(Y)\n",
    "    y_res = np.zeros(n)\n",
    "    t_res = np.zeros(n)\n",
    "    W = np.ones(n) if sample_weight is None else np.asarray(sample_weight)\n",
    "\n",
    "    # 预处理：weekday 做 OHE，merch份额直通\n",
    "    X_cat = [\"_weekday\"]\n",
    "    X_mer = [c for c in X_df.columns if str(c).startswith(\"mshare_\")]\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cat\", make_ohe(), X_cat),\n",
    "        (\"mer\", \"passthrough\", X_mer)\n",
    "    ])\n",
    "\n",
    "    for tr, te in kf.split(X_df):\n",
    "        Xt, Xv = X_df.iloc[tr], X_df.iloc[te]\n",
    "        Tt, Tv = T[tr], T[te]\n",
    "        Yt, Yv = Y[tr], Y[te]\n",
    "        Wt = W[tr]\n",
    "\n",
    "        Zt = pre.fit_transform(Xt)\n",
    "        Zv = pre.transform(Xv)\n",
    "\n",
    "        fY = RandomForestRegressor(n_estimators=400, n_jobs=-1, random_state=seed).fit(Zt, Yt, sample_weight=Wt)\n",
    "        fT = RandomForestRegressor(n_estimators=400, n_jobs=-1, random_state=seed).fit(Zt, Tt, sample_weight=Wt)\n",
    "\n",
    "        y_res[te] = Yv - fY.predict(Zv)\n",
    "        t_res[te] = Tv - fT.predict(Zv)\n",
    "\n",
    "    w = W / W.mean()\n",
    "    theta = np.average(t_res * y_res, weights=w) / np.average(t_res**2, weights=w)\n",
    "    return float(theta), t_res, y_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74dd2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment column: T_share_low_trim\n",
      "X columns (#): 21  →  ['_weekday', 'mshare_1', 'mshare_2', 'mshare_3', 'mshare_4', 'mshare_5', 'mshare_6', 'mshare_7'] ...\n",
      "T_share_low_trim    0.0\n",
      "Y_log_amt           0.0\n",
      "_weekday            0.0\n",
      "mshare_1            0.0\n",
      "mshare_2            0.0\n",
      "mshare_3            0.0\n",
      "mshare_4            0.0\n",
      "mshare_5            0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 关键列存在性\n",
    "req_cols = [\"_id\",\"_date\",\"T_share_low\",\"Y_log_amt\",\"_weekday\"]\n",
    "missing = [c for c in req_cols if c not in day_ip.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"缺少关键列: {missing}。请确认 02_build_inperson_day.ipynb 生成的表结构。\")\n",
    "\n",
    "# 若有修剪列就用修剪列；否则用原始占比\n",
    "T_col = \"T_share_low_trim\" if \"T_share_low_trim\" in day_ip.columns else \"T_share_low\"\n",
    "print(\"Treatment column:\", T_col)\n",
    "\n",
    "# 特征列：weekday + merch篮子份额\n",
    "X_cols = [\"_weekday\"] + [c for c in day_ip.columns if str(c).startswith(\"mshare_\")]\n",
    "print(\"X columns (#):\", len(X_cols), \" → \", X_cols[:8], \"...\" if len(X_cols)>8 else \"\")\n",
    "print(day_ip[[T_col, \"Y_log_amt\"] + X_cols].isna().mean().sort_values(ascending=False).head(8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055b427",
   "metadata": {},
   "source": [
    "# 加入 Rich CoVar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5eb340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using IND: ..\\data\\dcpc_2024_indlevel_public.csv\n",
      "Using DAY RAW: ..\\data\\dcpc_2024_daylevel_public.csv\n",
      "\n",
      "Selected ind-level features:\n",
      "['agerange', 'highest_education', 'work_occupation', 'hhincome', 'marital_status', 'workfullpart', 'inc_doyouget_employment', 'inc_doyouget_empretire', 'inc_doyouget_selfemployment', 'inc_doyouget_socsec', 'inc_doyouget_interest', 'inc_doyouget_rental', 'inc_doyouget_govtasst', 'inc_doyouget_alimony', 'inc_doyouget_childsupport', 'inc_doyouget_otherretire', 'inc_howoften_employment', 'inc_howoften_empretire', 'inc_howoften_selfemployment', 'inc_howoften_socsec', 'inc_howoften_interest', 'inc_howoften_rental', 'inc_howoften_govtasst', 'inc_howoften_alimony', 'inc_howoften_childsupport', 'inc_howoften_otherretire', 'work_employed', 'work_onleave', 'work_temp_unemployed', 'work_looking', 'work_retired', 'work_disabled', 'work_other', 'work_self']\n",
      "\n",
      "Selected day-state features:\n",
      "['inc_amnt_rental', 'inc_amnt_alimony', 'inc_amnt_childsupport', 'inc_amnt_otherretire', 'inc_method_employment', 'inc_method_empretire', 'inc_method_selfemployment', 'inc_method_socsec', 'inc_method_interest', 'inc_method_rental', 'inc_method_govtasst', 'inc_method_alimony', 'inc_method_childsupport', 'inc_method_otherretire', 'carry_paypal', 'numberofpayments', 'anypayments', 'nopayments']\n",
      "\n",
      "No 'day_max_txn' in day_ip, rebuilding from TRAN (STRICT rule)...\n",
      "\n",
      "'day_max_txn' describe:\n",
      "count     8247.000000\n",
      "mean       115.288655\n",
      "std        566.290133\n",
      "min          0.000000\n",
      "25%         17.245000\n",
      "50%         37.500000\n",
      "75%         81.000000\n",
      "max      30050.000000\n",
      "Name: day_max_txn, dtype: float64\n",
      "\n",
      "CAP = 50: kept 5065/8247 days  (61.4%)\n",
      "\n",
      "Rich X columns (dim=73):\n",
      "['_weekday', 'mshare_1', 'mshare_2', 'mshare_3', 'mshare_4', 'mshare_5', 'mshare_6', 'mshare_7', 'mshare_8', 'mshare_9', 'mshare_10', 'mshare_12', 'mshare_13', 'mshare_14', 'mshare_15', 'mshare_16', 'mshare_17', 'mshare_18', 'mshare_19', 'mshare_20', 'mshare_21', 'agerange', 'highest_education', 'work_occupation', 'hhincome', 'marital_status', 'workfullpart', 'inc_doyouget_employment', 'inc_doyouget_empretire', 'inc_doyouget_selfemployment', 'inc_doyouget_socsec', 'inc_doyouget_interest', 'inc_doyouget_rental', 'inc_doyouget_govtasst', 'inc_doyouget_alimony', 'inc_doyouget_childsupport', 'inc_doyouget_otherretire', 'inc_howoften_employment', 'inc_howoften_empretire', 'inc_howoften_selfemployment', 'inc_howoften_socsec', 'inc_howoften_interest', 'inc_howoften_rental', 'inc_howoften_govtasst', 'inc_howoften_alimony', 'inc_howoften_childsupport', 'inc_howoften_otherretire', 'work_employed', 'work_onleave', 'work_temp_unemployed', 'work_looking', 'work_retired', 'work_disabled', 'work_other', 'work_self', 'inc_amnt_rental', 'inc_amnt_alimony', 'inc_amnt_childsupport', 'inc_amnt_otherretire', 'inc_method_employment', 'inc_method_empretire', 'inc_method_selfemployment', 'inc_method_socsec', 'inc_method_interest', 'inc_method_rental', 'inc_method_govtasst', 'inc_method_alimony', 'inc_method_childsupport', 'inc_method_otherretire', 'carry_paypal', 'numberofpayments', 'anypayments', 'nopayments']\n",
      "\n",
      "Rich DML sample: rows = 0   persons = 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- 1. 找 ind/day 原始 CSV ----------\n",
    "IND_CANDS = [\n",
    "    Path(\"../data/dcpc_2024_indlevel_public.csv\"),\n",
    "]\n",
    "DAYRAW_CANDS = [\n",
    "    Path(\"../data/dcpc_2024_daylevel_public.csv\"),\n",
    "]\n",
    "TRAN_CANDS = [\n",
    "    Path(\"../data/dcpc_2024_tranlevel_public.csv\"),\n",
    "]\n",
    "\n",
    "def pick_path(cands):\n",
    "    for p in cands:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"File not found in candidates: \" + \", \".join(map(str, cands)))\n",
    "\n",
    "IND_PATH    = pick_path(IND_CANDS)\n",
    "DAYRAW_PATH = pick_path(DAYRAW_CANDS)\n",
    "print(\"Using IND:\", IND_PATH)\n",
    "print(\"Using DAY RAW:\", DAYRAW_PATH)\n",
    "\n",
    "ind_raw = pd.read_csv(IND_PATH, low_memory=False)\n",
    "day_raw = pd.read_csv(DAYRAW_PATH, low_memory=False)\n",
    "\n",
    "# ---------- 2. 对齐 id / date ----------\n",
    "# ind 对齐 _id\n",
    "id_ind = None\n",
    "for c in [\"_id\",\"id\",\"person_id\",\"PID\"]:\n",
    "    if c in ind_raw.columns:\n",
    "        id_ind = c\n",
    "        break\n",
    "if id_ind is None:\n",
    "    raise ValueError(\"ind-level 没找到 id 列\")\n",
    "\n",
    "ind_raw.rename(columns={id_ind: \"_id\"}, inplace=True)\n",
    "ind_raw[\"_id\"] = pd.to_numeric(ind_raw[\"_id\"], errors=\"coerce\")\n",
    "\n",
    "# day_raw 对齐 _id, _date\n",
    "id_day = None\n",
    "date_day = None\n",
    "for c in [\"_id\",\"id\",\"person_id\",\"PID\"]:\n",
    "    if c in day_raw.columns:\n",
    "        id_day = c\n",
    "        break\n",
    "for c in [\"_date\",\"date\",\"diary_date\"]:\n",
    "    if c in day_raw.columns:\n",
    "        date_day = c\n",
    "        break\n",
    "if id_day is None or date_day is None:\n",
    "    raise ValueError(\"day-level 没找到 id 或 date 列\")\n",
    "\n",
    "day_raw.rename(columns={id_day: \"_id\", date_day: \"_date\"}, inplace=True)\n",
    "day_raw[\"_id\"]   = pd.to_numeric(day_raw[\"_id\"], errors=\"coerce\")\n",
    "day_raw[\"_date\"] = pd.to_datetime(day_raw[\"_date\"], errors=\"coerce\")\n",
    "\n",
    "# 确保 day_ip 的 _date 是 datetime\n",
    "day_ip[\"_date\"] = pd.to_datetime(day_ip[\"_date\"], errors=\"coerce\")\n",
    "\n",
    "# ---------- 3. 从 ind 里挑几类直观特征 ----------\n",
    "# 用关键词自动挑一些列（income/education/age/household/employ）\n",
    "ind_keywords = [\"income\", \"inc_\", \"educ\", \"school\", \"age\", \"employ\", \"work\", \"job\",\n",
    "                \"hhsize\", \"household\", \"marital\", \"married\"]\n",
    "ind_cols = [c for c in ind_raw.columns\n",
    "            if any(kw in c.lower() for kw in ind_keywords)]\n",
    "\n",
    "# 去掉太高维的（比如全是 dummies 的那种），简单处理：排除 unique 太多的 id-like 列\n",
    "ind_cols = [c for c in ind_cols if ind_raw[c].nunique() < 50]\n",
    "\n",
    "print(\"\\nSelected ind-level features:\")\n",
    "print(ind_cols)\n",
    "\n",
    "ind_small = ind_raw[[\"_id\"] + ind_cols].copy()\n",
    "day_ip = day_ip.merge(ind_small, on=\"_id\", how=\"left\")\n",
    "\n",
    "# ---------- 4. 从 day_raw 里挑一些 \"day-state\" 特征 ----------\n",
    "# 比如 bill / pay / income / transfer 等\n",
    "day_keywords = [\"bill\", \"pay\", \"income\", \"inc_\", \"rent\", \"mortgage\", \"salary\", \"wage\"]\n",
    "day_state_cols = [c for c in day_raw.columns\n",
    "                  if any(kw in c.lower() for kw in day_keywords)]\n",
    "\n",
    "# 也简单限制一下维度\n",
    "day_state_cols = [c for c in day_state_cols if day_raw[c].nunique() < 50]\n",
    "\n",
    "print(\"\\nSelected day-state features:\")\n",
    "print(day_state_cols)\n",
    "\n",
    "day_small = day_raw[[\"_id\",\"_date\"] + day_state_cols].copy()\n",
    "day_ip = day_ip.merge(day_small, on=[\"_id\",\"_date\"], how=\"left\")\n",
    "\n",
    "# ---------- 5. 如果还没有 day_max_txn，就从 STRICT in-person 交易里算 ----------\n",
    "if \"day_max_txn\" not in day_ip.columns:\n",
    "    print(\"\\nNo 'day_max_txn' in day_ip, rebuilding from TRAN (STRICT rule)...\")\n",
    "    TRAN_PATH = pick_path(TRAN_CANDS)\n",
    "    tran = pd.read_csv(TRAN_PATH, low_memory=False)\n",
    "    \n",
    "    # 对齐 id/date/amount\n",
    "    id_tr = None\n",
    "    date_tr = None\n",
    "    amt_tr = None\n",
    "    for c in [\"_id\",\"id\",\"person_id\",\"PID\"]:\n",
    "        if c in tran.columns:\n",
    "            id_tr = c\n",
    "            break\n",
    "    for c in [\"_date\",\"date\"]:\n",
    "        if c in tran.columns:\n",
    "            date_tr = c\n",
    "            break\n",
    "    for c in [\"_amount\",\"amnt\",\"amount\"]:\n",
    "        if c in tran.columns:\n",
    "            amt_tr = c\n",
    "            break\n",
    "    if id_tr is None or date_tr is None or amt_tr is None:\n",
    "        raise ValueError(\"TRAN 缺少 id/date/amount 列，无法重建 day_max_txn\")\n",
    "\n",
    "    tran.rename(columns={id_tr:\"_id\", date_tr:\"_date\", amt_tr:\"_amount\"}, inplace=True)\n",
    "    tran[\"_id\"]   = pd.to_numeric(tran[\"_id\"], errors=\"coerce\")\n",
    "    tran[\"_date\"] = pd.to_datetime(tran[\"_date\"], errors=\"coerce\")\n",
    "    tran[\"_amount\"] = pd.to_numeric(tran[\"_amount\"], errors=\"coerce\")\n",
    "\n",
    "    # 只保留真实支付 + in-person\n",
    "    is_payment = (tran.get(\"payment\", 1) == 1) & (tran.get(\"nonpaymenttran\").isna())\n",
    "    tran = tran[is_payment].copy()\n",
    "    tran[\"_inperson\"] = pd.to_numeric(tran.get(\"in_person\"), errors=\"coerce\")\n",
    "    tran = tran[tran[\"_inperson\"] == 1].copy()\n",
    "\n",
    "    # STRICT PI 规则\n",
    "    tran[\"pi\"] = pd.to_numeric(tran.get(\"pi\"), errors=\"coerce\")\n",
    "    STRICT_LOW  = {3,4,6,7}\n",
    "    STRICT_HIGH = {1,2,8}\n",
    "    STRICT_KEEP = STRICT_LOW | STRICT_HIGH\n",
    "    tran = tran[tran[\"pi\"].isin(STRICT_KEEP)].copy()\n",
    "\n",
    "    gmax = tran.groupby([\"_id\",\"_date\"])[\"_amount\"].max().rename(\"day_max_txn\")\n",
    "    day_ip = day_ip.merge(gmax, on=[\"_id\",\"_date\"], how=\"left\")\n",
    "\n",
    "print(\"\\n'day_max_txn' describe:\")\n",
    "print(day_ip[\"day_max_txn\"].describe())\n",
    "\n",
    "# ---------- 6. 设置价格 cap (单日最大单笔) ----------\n",
    "CAP = 50   # 你可以改成 200 看 sensitivity\n",
    "day_cap = day_ip[day_ip[\"day_max_txn\"].notna() & (day_ip[\"day_max_txn\"] <= CAP)].copy()\n",
    "print(f\"\\nCAP = {CAP}: kept {len(day_cap)}/{len(day_ip)} days  ({len(day_cap)/len(day_ip):.1%})\")\n",
    "\n",
    "# ---------- 7. 构造 Rich X & 分析样本 ----------\n",
    "X_cols_rich = ([\"_weekday\"]\n",
    "               + [c for c in day_cap.columns if str(c).startswith(\"mshare_\")]\n",
    "               + ind_cols\n",
    "               + day_state_cols)\n",
    "\n",
    "# 去重防万一\n",
    "X_cols_rich = list(dict.fromkeys(X_cols_rich))\n",
    "\n",
    "print(\"\\nRich X columns (dim={}):\".format(len(X_cols_rich)))\n",
    "print(X_cols_rich)\n",
    "\n",
    "sub_rich = day_cap.dropna(subset=[T_col, \"Y_log_amt\"] + X_cols_rich).copy()\n",
    "print(\"\\nRich DML sample: rows =\", len(sub_rich), \"  persons =\", sub_rich[\"_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18237db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering, X_cols_rich dim = 73\n",
      "After intersect with day_cap, dim = 73\n",
      "\n",
      "Top 20 rich features by non-missing rate:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nnz_rate</th>\n",
       "      <th>nuniq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mshare_13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_weekday</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mshare_5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                nnz_rate  nuniq\n",
       "mshare_13            1.0      5\n",
       "mshare_14            1.0      5\n",
       "mshare_15            1.0      5\n",
       "mshare_19            1.0      5\n",
       "mshare_10            1.0      6\n",
       "mshare_12            1.0      6\n",
       "marital_status       1.0      6\n",
       "_weekday             1.0      7\n",
       "mshare_8             1.0      7\n",
       "mshare_17            1.0      8\n",
       "mshare_18            1.0      8\n",
       "mshare_9             1.0      9\n",
       "mshare_16            1.0      9\n",
       "mshare_20            1.0     10\n",
       "mshare_21            1.0     11\n",
       "mshare_6             1.0     12\n",
       "mshare_7             1.0     12\n",
       "mshare_2             1.0     15\n",
       "mshare_3             1.0     16\n",
       "mshare_5             1.0     17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered rich X (nnz >= 0.80, nuniq > 1) → dim = 44\n",
      "['_weekday', 'mshare_1', 'mshare_2', 'mshare_3', 'mshare_4', 'mshare_5', 'mshare_6', 'mshare_7', 'mshare_8', 'mshare_9', 'mshare_10', 'mshare_12', 'mshare_13', 'mshare_14', 'mshare_15', 'mshare_16', 'mshare_17', 'mshare_18', 'mshare_19', 'mshare_20', 'mshare_21', 'highest_education', 'hhincome', 'marital_status', 'inc_doyouget_employment', 'inc_doyouget_empretire', 'inc_doyouget_selfemployment', 'inc_doyouget_socsec', 'inc_doyouget_interest', 'inc_doyouget_rental', 'inc_doyouget_govtasst', 'inc_doyouget_alimony', 'inc_doyouget_childsupport', 'inc_doyouget_otherretire', 'work_employed', 'work_onleave', 'work_temp_unemployed', 'work_looking', 'work_retired', 'work_disabled', 'work_other', 'carry_paypal', 'numberofpayments', 'anypayments']\n",
      "\n",
      "Rich DML sample after filtering:\n",
      "  rows   = 4298\n",
      "  persons= 3039\n"
     ]
    }
   ],
   "source": [
    "# === Debug + 修复 X_cols_rich，避免 sub_rich 变成空 ===\n",
    "print(\"Before filtering, X_cols_rich dim =\", len(X_cols_rich))\n",
    "\n",
    "# 1. 只保留 day_cap 里确实存在的列（防止误选不存在的）\n",
    "X_cols_rich = [c for c in X_cols_rich if c in day_cap.columns]\n",
    "print(\"After intersect with day_cap, dim =\", len(X_cols_rich))\n",
    "\n",
    "# 2. 计算每个候选特征的非缺失比例 & 唯一值个数\n",
    "na_rate = day_cap[X_cols_rich].isna().mean()\n",
    "nnz_rate = 1 - na_rate\n",
    "nuniq = day_cap[X_cols_rich].nunique(dropna=True)\n",
    "\n",
    "diag = pd.DataFrame({\n",
    "    \"nnz_rate\": nnz_rate,\n",
    "    \"nuniq\": nuniq\n",
    "}).sort_values([\"nnz_rate\",\"nuniq\"], ascending=[False, True])\n",
    "\n",
    "print(\"\\nTop 20 rich features by non-missing rate:\")\n",
    "display(diag.head(20))\n",
    "\n",
    "# 3. 过滤规则\n",
    "#    - 至少 80% 的非缺失\n",
    "#    - 至少 2 个取值（排除全是常数/全 0 列）\n",
    "MIN_NNZ = 0.80\n",
    "X_keep = [c for c in X_cols_rich\n",
    "          if nnz_rate[c] >= MIN_NNZ and nuniq[c] > 1]\n",
    "\n",
    "print(f\"\\nFiltered rich X (nnz >= {MIN_NNZ:.2f}, nuniq > 1) → dim =\", len(X_keep))\n",
    "print(X_keep)\n",
    "\n",
    "# 4. 用过滤后的 X_keep 重建 sub_rich\n",
    "X_cols_rich = X_keep\n",
    "sub_rich = day_cap.dropna(subset=[T_col, \"Y_log_amt\"] + X_cols_rich).copy()\n",
    "\n",
    "print(\"\\nRich DML sample after filtering:\")\n",
    "print(\"  rows   =\", len(sub_rich))\n",
    "print(\"  persons=\", sub_rich[\"_id\"].nunique())\n",
    "\n",
    "# 如果样本还是太少，可以考虑：\n",
    "#  - 降低 MIN_NNZ，比如 0.2\n",
    "#  - 或者先不加某一大类的 ind/day 特征，分步加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c794f3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DML rich X, cap=50] theta=0.3384  95%CI=(0.2907,0.3968)  → per +10pp ≈ 3.4%   (B=10)\n",
      "Rows used: 4298   Unique persons: 3039\n"
     ]
    }
   ],
   "source": [
    "th, ci, B_used = cluster_bootstrap_theta(\n",
    "    sub_rich,\n",
    "    X_cols=X_cols_rich,\n",
    "    T_col=T_col,\n",
    "    Y_col=\"Y_log_amt\",\n",
    "    B=10,\n",
    "    seed=2027,\n",
    "    use_day_weight=(\"w_day\" in sub_rich.columns)\n",
    ")\n",
    "delta10 = 0.10 * th\n",
    "rel_pct = (np.exp(delta10) - 1) * 100\n",
    "print(f\"[DML rich X, cap={CAP}] theta={th:.4f}  95%CI=({ci[0]:.4f},{ci[1]:.4f})  → per +10pp ≈ {rel_pct:.1f}%   (B={B_used})\")\n",
    "print(\"Rows used:\", len(sub_rich), \"  Unique persons:\", sub_rich['_id'].nunique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
